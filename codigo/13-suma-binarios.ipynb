{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bound-beach",
   "metadata": {},
   "source": [
    "# Suma de numeros binarios\n",
    "\n",
    "El objetivo de esta práctica es diseñar un modelo recurrente basado en modelos de redes neuronales (RNN). Empecemos por cargar las librerías necesarias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "timely-release",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:08:21.236242Z",
     "start_time": "2021-05-05T15:08:21.232792Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-public",
   "metadata": {},
   "source": [
    "La idea es sencilla. Todo número entero tiene una representación binaria. Por ejemplo, \n",
    "el número `43` tiene una representación binaria igual a `1101010`. La cual podemos representar como un expansión en potencias de 2. Es decir, \n",
    "\n",
    "$${\\color{blue}1} \\times 2^0 + {\\color{blue}1}\\times2^1+ {\\color{blue}0}\\times 2^2 + {\\color{blue}1}\\times 2^3 + {\\color{blue}0}\\times 2^4+ {\\color{blue}1}\\times2^5+ {\\color{blue}0}\\times2^6$$ \n",
    "\n",
    "El objetivo es, dados dos números en binario ($x_1, x_2$) queremos entrenar una RNN para producir el resultado $y = x_1 + x_2.$\n",
    "\n",
    "Por ejemplo, tenemos los siguientes dos números:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "worse-stamp",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:37:58.176334Z",
     "start_time": "2021-05-05T15:37:58.172244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 43]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "x1 = np.random.randint(0, 2**(7-1))\n",
    "x2 = np.random.randint(0, 2**(7-1))\n",
    "\n",
    "print(\"[%d, %d]\"%(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-sector",
   "metadata": {},
   "source": [
    "Que si sumamos tenemos como resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "sudden-mills",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:38:45.642105Z",
     "start_time": "2021-05-05T15:38:45.638703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 + x2 = 80\n"
     ]
    }
   ],
   "source": [
    "print(\"x1 + x2 = %d\"%(x1+x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-washer",
   "metadata": {},
   "source": [
    "Lo que queremos hacer es encontrar una función (RNN) que \"sepa\" sumar en representación binaria. Es decir, utilizando la representación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "established-amsterdam",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:45:54.682903Z",
     "start_time": "2021-05-05T15:45:54.678703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 =  1010010\n",
      "x2 =  1101010\n"
     ]
    }
   ],
   "source": [
    "format_str = '{:0' + str(sequence_len) + 'b}'\n",
    "\n",
    "print(\"x1 = \", ''.join(list(reversed(format_str.format(x1)))))\n",
    "print(\"x2 = \", ''.join(list(reversed(format_str.format(x2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "third-haven",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:46:34.254970Z",
     "start_time": "2021-05-05T15:46:34.251267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 + x2 =  0000101\n"
     ]
    }
   ],
   "source": [
    "print(\"x1 + x2 = \", ''.join(list(reversed(format_str.format(x1 + x2)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-temple",
   "metadata": {},
   "source": [
    "**Nota** que estamos utilizando la convención de escribir un número binario en potencias crecientes de 2. La suma binaria en este caso es una operación que va de izquierda a derecha. Con las reglas usuales: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "0 + 0 &= 0\\,,\\\\\n",
    "1 + 0 &= 1\\,,\\\\\n",
    "0 + 1 &= 1\\,.\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "El caso $1 + 1 = 10$ es el mas interesante, pues en un modelo secuencial que predice un digito a la vez tendría que asignar un `0` y \"saber\" que \"lleva\" un `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-morocco",
   "metadata": {},
   "source": [
    "Vamos a escribir el modelo mas sencillo que podamos. Para esto consideramos lo siguiente. La suma binaria la entendemos digito por digito y con esto tratamos de decidir si emitimos un `0` o un `1`. Para esta parte supondremos que sumamos número pequeños. \n",
    "\n",
    "**Q1** ¿Cuál es el número más grande que podemos encontrar si generamos numeros binarias de longitud igual a 7?\n",
    "\n",
    "**Q2** Llena los espacios que faltan en el codigo de abajo para definir un modelo RNN simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "approximate-deposit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:08:33.746303Z",
     "start_time": "2021-05-05T16:08:33.663637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 2)\n",
      "(None, None, 1)\n"
     ]
    }
   ],
   "source": [
    "MAX_BIT = 7\n",
    "\n",
    "\n",
    "input_dim = # El numero de dimensiones de entrada.\n",
    "activation = # Una cadena de texto especificando la función de activación en la capa de salida. \n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.SimpleRNN(\n",
    "    4,\n",
    "    input_dim        = input_dim,\n",
    "    return_sequences = True\n",
    "))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation=activation))\n",
    "\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-actress",
   "metadata": {},
   "source": [
    "**Q3** Prueba que el modelo funciona con un ejemplo sencillo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-convertible",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:15:05.552406Z",
     "start_time": "2021-05-05T15:15:05.381772Z"
    }
   },
   "outputs": [],
   "source": [
    "# test if the prediction shape are expected\n",
    "input_array = #\n",
    "x = np.array([input_array])\n",
    "print(x.shape)\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-republican",
   "metadata": {},
   "source": [
    "Para evitar que el codigo sea demasiado complejo, puedes utilizar las siguientes funciones que modifican las entradas para representarlas en binarios. Nota que necesitamos una función adicional para hacer _padding_ y rellenar con ceros la secuencia cuando el número es muy pequeño relativo a la longitud de potencias que estamos utilizando.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "iraqi-touch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:15:06.083844Z",
     "start_time": "2021-05-05T15:15:06.078963Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.sequence\n",
    "\n",
    "def to_seq(i):\n",
    "    return list(reversed(list(map(float, \"{0:b}\".format(i)))))\n",
    "\n",
    "def pad_seq(a, b, c, maxlen=None):\n",
    "    return keras.preprocessing.sequence.pad_sequences(\n",
    "        [a, b, c],\n",
    "        padding='post',\n",
    "        dtype='float32',\n",
    "        maxlen=maxlen\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-gross",
   "metadata": {},
   "source": [
    "Abajo encontrarás dos funciones mas para generar conjuntos de datos para entrenar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "medieval-ideal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:15:07.697528Z",
     "start_time": "2021-05-05T15:15:07.691154Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_sample(a = None, b = None):\n",
    "    maxlen = None\n",
    "    if a is None and b is None:\n",
    "        a = np.random.randint(2 ** MAX_BIT)\n",
    "        b = np.random.randint(2 ** MAX_BIT)\n",
    "        maxlen = MAX_BIT + 1\n",
    "    c = a + b\n",
    "    a, b, c = pad_seq(to_seq(a), to_seq(b), to_seq(c), maxlen=maxlen)\n",
    "\n",
    "    return np.array(list(zip(a, b))), c\n",
    "def gen_mass_samples(n = 50):\n",
    "    x = np.zeros((n, MAX_BIT + 1, 2))\n",
    "    y = np.zeros((n, MAX_BIT + 1, 1))\n",
    "    for i in range(n):\n",
    "        x_, y_ = gen_sample()\n",
    "        x[i, :, :] = x_\n",
    "        y[i, :, :] = y_.reshape(1, -1, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "missing-devon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T15:15:08.291827Z",
     "start_time": "2021-05-05T15:15:08.276446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 11, 2)\n",
      "(50, 11, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([1., 0.]), array([1.])),\n",
       " (array([0., 0.]), array([0.])),\n",
       " (array([1., 0.]), array([1.])),\n",
       " (array([1., 1.]), array([0.])),\n",
       " (array([0., 0.]), array([1.])),\n",
       " (array([1., 0.]), array([1.])),\n",
       " (array([1., 1.]), array([0.])),\n",
       " (array([1., 0.]), array([0.])),\n",
       " (array([0., 0.]), array([1.])),\n",
       " (array([1., 0.]), array([1.])),\n",
       " (array([0., 0.]), array([0.]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_mass_samples()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "list(zip(x[0], y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-ratio",
   "metadata": {},
   "source": [
    "El siguiente pedazo de código entrena el modelo con elecciones _default_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "steady-property",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:15:46.895869Z",
     "start_time": "2021-05-05T16:15:20.509516Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 9.6441e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.8063e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.0496e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 7.3638e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.7414e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.1751e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.6600e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.1894e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.7598e-04 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.3487e-04 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 3.9913e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.6651e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.3665e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.0932e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.8419e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.6126e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.4008e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.2068e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.0292e-04 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.8827e-04 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.7881e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.5844e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.4537e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.3351e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.2280e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.1286e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.0382e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 9.5471e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.7880e-05 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 8.1443e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 7.4883e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.8845e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 6.3317e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.8277e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 5.3621e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 4.9290e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.5367e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 4.1701e-05 - accuracy: 1.0000: 0s - loss: 4.1966e-05 - accuracy: 1.00\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.8380e-05 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.5220e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 3.2358e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.9777e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.7407e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.5225e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.3218e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 2.1369e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.9669e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.8104e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6663e-05 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.5426e-05 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4193e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.3044e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.2004e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.1044e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.0163e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 9.3540e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 8.6086e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 7.9225e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 7.2942e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "N = 10000\n",
    "for i in range(8):\n",
    "    x, y = gen_mass_samples(N)\n",
    "    model.fit(x.reshape(N, -1, 2), y.reshape(N, -1, 1), batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "discrete-bidder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T16:15:53.448440Z",
     "start_time": "2021-05-05T16:15:50.799646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 834us/step - loss: 6.9630e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.962984116398729e-06, 1.0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_mass_samples(N * 3)\n",
    "model.evaluate(x.reshape(N * 3, -1, 2), y.reshape(N * 3, -1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-quest",
   "metadata": {},
   "source": [
    "**Q4** Escribe un ejemplo para verificar la capacidad predictiva del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "working-banking",
   "metadata": {},
   "source": [
    "**Q5** Copia y pega el código necesario y entrena el modelo con números mas grandes. Evalúa la capacidad predictiva del modelo en este escenario (números grandes, por ejemplo longitud en binario = 30). ¿Porqué crees que ocurra esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-scholar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "passing-mainland",
   "metadata": {},
   "source": [
    "**Q6** Extiende el modelo para incorporar celdas de memoria y evalúa si el fenomeno que observaste en la pregunta anterior sigue persistiendo (posiblemente tengas que incrementar el número de epocas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-invalid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
